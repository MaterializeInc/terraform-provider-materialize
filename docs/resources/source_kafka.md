---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "materialize_source_kafka Resource - terraform-provider-materialize"
subcategory: ""
description: |-
  A source describes an external system you want Materialize to read data from, and provides details about how to decode and interpret that data.
---

# materialize_source_kafka (Resource)

A source describes an external system you want Materialize to read data from, and provides details about how to decode and interpret that data.

## Example Usage

```terraform
resource "materialize_source_kafka" "example_source_kafka" {
  name                       = "source_kafka"
  schema_name                = "schema"
  size                       = "3xsmall"
  kafka_connection           = "kafka_connection"
  schema_registry_connection = "csr_connection"
  format                     = "AVRO"
  envelope                   = "data"
}

# CREATE SOURCE kafka_metadata
#   FROM KAFKA CONNECTION kafka_connection (TOPIC 'data')
#   FORMAT AVRO USING CONFLUENT SCHEMA REGISTRY CONNECTION csr_connection
#   ENVELOPE NONE
#   WITH (SIZE = '3xsmall');
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `format` (String) How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
- `kafka_connection` (String) The name of the Kafka connection to use in the source.
- `name` (String) The identifier for the source.
- `topic` (String) The Kafka topic you want to subscribe to.

### Optional

- `cluster_name` (String) The cluster to maintain this source. If not specified, the size option must be specified.
- `database_name` (String) The identifier for the source database.
- `envelope` (String) How Materialize should interpret records (e.g. append-only, upsert).
- `include_headers` (Boolean) Include message headers.
- `include_key` (String) Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
- `include_offset` (String) Include an offset column containing the Kafka message offset.
- `include_partition` (String) Include a partition column containing the Kafka message partition
- `include_timestamp` (String) Include a timestamp column containing the Kafka message timestamp.
- `key_format` (String) Set the key and value encodings explicitly.
- `key_strategy` (String) How Materialize will define the Avro schema reader key strategy.
- `primary_key` (List of String) Declare a set of columns as a primary key.
- `schema_name` (String) The identifier for the source schema.
- `schema_registry_connection` (String) The name of a schema registry connection.
- `size` (String) The size of the source.
- `start_offset` (List of Number) Read partitions from the specified offset.
- `start_timestamp` (Number) Use the specified value to set "START OFFSET" based on the Kafka timestamp.
- `value_strategy` (String) How Materialize will define the Avro schema reader value strategy.

### Read-Only

- `id` (String) The ID of this resource.
- `qualified_name` (String) The fully qualified name of the source.

## Import

Import is supported using the following syntax:

```shell
# Sources can be imported using the source id:
terraform import materialize_source_kafka.example_source_kafka <source_id>
```
