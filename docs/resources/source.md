---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "materialize_source Resource - terraform-provider-materialize"
subcategory: ""
description: |-
  A source describes an external system you want Materialize to read data from, and provides details about how to decode and interpret that data.
---

# materialize_source (Resource)

A source describes an external system you want Materialize to read data from, and provides details about how to decode and interpret that data.

## Example Usage

```terraform
resource "materialize_source" "example_source_load_generator" {
  name                = "source_load_generator"
  schema_name         = "schema"
  size                = "3xsmall"
  connection_type     = "LOAD GENERATOR"
  load_generator_type = "COUNTER"
  tick_interval       = "500ms"
  scale_factor        = 0.01
}

# CREATE SOURCE schema.source_load_generator
#   FROM LOAD GENERATOR COUNTER
#   (TICK INTERVAL '500ms' SCALE FACTOR 0.01)
#   WITH (SIZE = '3xsmall');

resource "materialize_source" "example_source_postgres" {
  name                = "source_postgres"
  schema_name         = "schema"
  size                = "3xsmall"
  connection_type     = "POSTGRES"
  postgres_connection = "pg_connection"
  publication         = "mz_source"
  tables = {
    "schema1.table_1" = "s1_table_1"
    "schema2_table_1" = "s2_table_1"
  }
}

# CREATE SOURCE schema.source_postgres
#   FROM POSTGRES CONNECTION pg_connection (PUBLICATION 'mz_source')
#   FOR TABLES (schema1.table_1 AS s1_table_1, schema2_table_1 AS s2_table_1)
#   WITH (SIZE = '3xsmall');

resource "materialize_source" "example_source_kafka" {
  name                       = "source_kafka"
  schema_name                = "schema"
  size                       = "3xsmall"
  connection_type            = "KAFKA"
  kafka_connection           = "kafka_connection"
  schema_registry_connection = "csr_connection"
  format                     = "AVRO"
  envelope                   = "data"
}

# CREATE SOURCE kafka_metadata
#   FROM KAFKA CONNECTION kafka_connection (TOPIC 'data')
#   FORMAT AVRO USING CONFLUENT SCHEMA REGISTRY CONNECTION csr_connection
#   ENVELOPE NONE
#   WITH (SIZE = '3xsmall');
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `connection_type` (String) The source connection type.
- `name` (String) The identifier for the source.

### Optional

- `cluster_name` (String) The cluster to maintain this source. If not specified, the size option must be specified.
- `database_name` (String) The identifier for the source database.
- `envelope` (String) How to interpret records (e.g. Append Only, Upsert).
- `format` (String) How to decode raw bytes from different formats into data structures it can understand at runtime
- `include_key` (String) Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named key.
- `include_offset` (String) Include an offset column containing the Kafka message offset.
- `include_partition` (String) Include a partition column containing the Kafka message partition
- `include_timestamp` (String) Include a timestamp column containing the Kafka message timestamp.
- `kafka_connection` (String) The name of the Kafka connection to use in the source.
- `load_generator_type` (String) The identifier for the secret schema.
- `postgres_connection` (String) The name of the PostgreSQL connection to use in the source.
- `publication` (String) The PostgreSQL publication (the replication data set containing the tables to be streamed to Materialize).
- `scale_factor` (Number) The scale factor for the TPCH generator. Defaults to 0.01 (~ 10MB).
- `schema_name` (String) The identifier for the source schema.
- `schema_registry_connection` (String) The name of the connection to use for the shcema registry.
- `size` (String) The size of the source.
- `tables` (Map of String) Creates subsources for specific tables in the load generator.
- `tick_interval` (String) The interval at which the next datum should be emitted. Defaults to one second.
- `topic` (String) The Kafka topic you want to subscribe to.

### Read-Only

- `id` (String) The ID of this resource.

## Import

Import is supported using the following syntax:

```shell
# Sources can be imported using the source id:
terraform import materialize_source.example_source_load_generator <source_id>
```
